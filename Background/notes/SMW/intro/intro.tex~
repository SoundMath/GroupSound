% -*- mode: LaTeX; tex-main-file: "../notes.tex"; -*-
%\begin{itemize}
%\item Synthesis -- Sethares (p.15), comp book (00.07.17), beige book (00.07.27)
%\item Tonal Fusion -- comp book (00.07.10)
%\item Spectral Dominance -- Hartmann (p.298) and beige book (00.07.11)
%\item Tonal Dissonance -- comp book (00.07.21)
%\item Wavelet Theory -- beige book (00.07.31, 00.08.01, 00.08.02)
%\end{itemize}
%\input{\HOME/intro/quote.tex}
\section{Introduction}
\subsection{Analysis of Non-stationary Signals}
There is a vast literature on the analysis of signals -- be they
musical or not.  The broad class of analysis methods that we study here
consists of {\it time-frequency representations}.  The type of signal
which concerns us is a {\it time series}, $x(t)$.  In other words, it
is a function of a single time variable, $t$.  Often there is reason
to believe that periodicities play an important role in the structure
of $x(t)$.  To study the signal from this point of view, we decompose
it as a function of both time and frequency. Such a decomposition is
what we mean by a time-frequency representation (TFR).

The two broad classes of TFR's which we consider are {\it atomic
decompostions} and {\it energy distributions}.  The first decomposes a
signal by ``projecting'' it onto the time-frequency space, thereby equating
it with a weighted sum of basic elements in that space. (These basic elements
do not always comprise a {\it basis} -- a full set of orthonormal 
elements -- and, in such cases, the decomposition is not a true projection.)
A few more comments about atomic decompositions appear below, but a more
detailed discussion appears is section~\ref{sec:atomic}.

The second class of TFR's are the energy distributions, the primary
objective of which is to represent a distribution of the signal's energy
across the time-frequency plane.  We consider the energy distributions in
section~\ref{sec:energy}. 

Before proceeding, let's consider some general, motivating comments
concerning the use of atomic decompositions for our application.  The
primary consideration for such analyses is the selection an appropriate
basis for processing a particular class of signals.  
%\begin{quote}
The decomposition coefficients of a signal in a basis define a representation 
that highlights some particular signal properties.  For example, wavelet
coefficients provide explicit information on the location and type of signal
singularities.  The problem is to find a criterion for selecting a basis that
is intrinsically well adapted to represent a class of signals.
%\end{quote}

Using classical Fourier analysis, a signal $x$ can be decomposed as a
weighted sum of sinusoidal functions, $\{e^{i2\pi \xi t}\}$,
\[
x(t) = %\frac{1}{2\pi}
\integral X(\xi) e^{i2\pi \xi t}\, d\xi
\]
with weights (amplitudes) given by the Fourier transform
%$X(\xi)$, 
of $x$:
\begin{equation}
\label{eqn:ft}
X(\xi) = \int_{-\infty}^{\infty}x(t) e^{-i2\pi \xi t}\, dt
\end{equation}
If our focus is limited to stationary signals whose frequency contents
do not change dramatically with time, the Fourier analysis provides
simple answers to most questions.  However, we are interested in
representing transient phenomena -- e.g.~a sudden change or singularity in a 
musical signal -- and the Fourier transform is the wrong tool for the job.

The Fourier coefficient in~(\ref{eqn:ft}) is obtained by correlating $x$
with a sinusoidal wave $e^{i2\pi\xi t}$.  Since the support 
of $e^{i2\pi\xi t}$ covers the whole real line, $X(\xi)$ depends 
on the values $x(t)$ for all times $t \in \R$.  This global ``mix'' of
information makes it difficult to analyze any local property of $x$
from $X$.  We need to consider using local time-frequency
transforms, such as the windowed Fourier transform and wavelet
transform, which decompose the signal over waveforms that are well
localized in both frequency and time.

Though wavelet and windowed Fourier techniques can be effectivly applied to
non-stationary signals, they suffer from the adverse consequences of
Heisenberg's uncertainty principle (we discuss this problem in section 

\subsection{Objective}
The primary objective of this work is to derive useful methods and software
routines for \emph{perception analyses} of a piece of music, $x(t)$.
We consider traditional signal analysis methods in light of this objective,
and focus on those methods which
%a piece of music in such a way that 
facilitate measures of perceived qualities of music.  More specifically, we
consider how signal energy densities relate to a quantitative measure of
\emph{sensory dissonance}, which we define in section~\ref{sec:consonance}. 

To reach our objective requires that we overcome a number of interelated
challenges.  The primary tasks involved are as follows:
\begin{enumerate}
\item \label{item:spectral} Find useful time-frequency representations for
  analyzing the information content of $x(t)$, with the goal of characterizing
  perceptual  properties of the signal.
\item \label{item:dissonance} Exploiting the analyses of~\ref{item:spectral},
  derive measures of qualities related to human perception of the signal.
  Derive the ``consonance signature'' of $x(t)$. 
\item Create methods for altering the consonance signature of $x(t)$, by
  manipulating the structure of its time-frequency representation (e.g.~using
  time-frequency transformations).
\end{enumerate}

Our approach to (\ref{item:spectral}) considers the atomic decompositions
(e.g.~windowed Fourier or wavelet analysis), as well as energy distributions. 
Concerning the former, the ``grains'' of \emph{granular synthesis} (Cavalierre
and Piccialli~\cite{Cavaliere:1997},~\cite{Roads:1997}) usually represent
segments of the signal that extend beyond a single period. The goal is to
capture the pseudo-periodic component of the signal. For wavelet analyses, we
could attempt to find a basis whose elements are closely correlated with the
components of the signal having the greatest ``periodic endurance.''
We decompose the signal into its quasi-harmonic part (wavelet
components) and its \emph{transients} (error terms, deviations,
microvariants):
\[
x(t) = \P_{\mathcal{M}}[x](t) 
       + [x(t) - \P_{\mathcal{M}}[x](t)]
\]
The first term on the right is the orthogonal projection of $x$
onto the ``harmonic'' subspace $\mathcal{M}$.  The second term
accounts for the part of $x$ that is orthogonal to the harmonic
subspace (i.e.~the transients).

To address item (\ref{item:dissonance}), we might consider various
decompositions of frequency space $F,$ for instance, as a direct sum
of subspaces $\{S_1, S_2, \ldots, S_N\}$: 
\[ F = S_1 \oplus S_2 \oplus \cdots \oplus S_N\]
where each $S_k$ defines a \emph{subspace of great consonance.}
This could be taken to mean that tones occurring within 
the same subspace, say $x \in S_k$ and  $x' \in S_k,$ are relatively
consonant, while $x$ and  
$y \in S_{k+1}$ are relatively dissonant.  We could also specify some
properties that such subspaces should posses. For example, let $S_k$
and $S_{k+1}$ be two distinct subspaces of great consonance and
suppose $x \in S_k$ and $y \in S_{k+1}$.  Then, 
\[
D(x,x') \leq D(x,y) \mbox{ for any } x' \in S_k
\] 
More precisely, this is a property of the \emph{dissonance metric}
$D(\cdot,\cdot)$ defined on the space, which leads us to the issue of how
dissonance ought to be defined.

% (begin: input from icassp paper, file Intro.tex}

The concept of \emph{sensory dissonance} was originally proposed
by Helmholtz \cite{Helmholtz:1877}, and further developed by Plomp and 
Levelt~\cite{Plomp:1965}, and Sethares~\cite{Sethares:1997}.
Though we consider these studies in greater detail in
sections~\ref{sec:consonance} and~\ref{sec:disscurves}, what follows
is a descriptions that motivates our alternative treatment of this
subject. 

In order to assess the intrinsic dissonance of a musical signal over a
small time interval, the forementioned studies employ a function of
the the signal's estimated frequency components over that interval.
This often provides a useful quantitative measure.  However, such a
function makes no attempt to account for other widely accepted notions
of dissonance.   
Perhaps the most obvious short-coming results from the point-wise
nature of the dissonance function.  That is, because it is
well localized in time, the dissonance function does not 
measure the \emph{melodic dissonance} of the signal.  The melodic
dissonance of a given segment of music depends on that 
segment's relation to its context.  In our present work, we
consider signal analysis methods that provide for
%estimates of
%instantaneous frequencies and analytic amplitudes of a signal, and use 
%these estimates to measure the dissonance properties of the
%signal.  A primary objective is the development of methods providing
more dynamic dissonance measures, simultaneously accounting for local
dissonance as well as melodic contour.

% (end: input from icassp paper, file Intro.tex}
